{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wordcloud) (1.19.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wordcloud) (3.3.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wordcloud) (8.0.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "!pip install wordcloud\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import re #регулярки для проверки на латиницу\n",
    "import string\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation =string.punctuation +'–'\n",
    "#короткое тире - часть слова\n",
    "re_punctuation = '!\"#$%&\\'()*+,./:;<=>?@~–^_`{|}—»«'\n",
    "numbers = '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class meaningless_words:\n",
    "    def __init__(self, russian_stopwords = stopwords.words('russian'), english_stopwords = stopwords.words('english')):\n",
    "        self.universal = set(russian_stopwords) | set(english_stopwords )\n",
    "        self.russian = set(russian_stopwords)\n",
    "        self.english = set(english_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageException(BaseException):\n",
    "    def __init__(self, problem = ''):\n",
    "        self.problem = problem\n",
    "    def __str__(self):\n",
    "        return str(self.problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language:\n",
    "    def __init__(self, *args):\n",
    "        self.universal = 'universal'\n",
    "        self.russian = 'russian'\n",
    "        self.english = 'english'\n",
    "        self.сyrillic = 'russian'\n",
    "        self.latin = 'english'\n",
    "        self.other = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_meaningless_words = meaningless_words()\n",
    "language = Language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_words(text):\n",
    "    \n",
    "    only_words = re.sub('[' +re_punctuation + '\\n' + numbers +']', ' ', text.lower())\n",
    "    only_words = re.sub('\\s-+\\s', ' ', only_words)\n",
    "    return only_words\n",
    "\n",
    "\n",
    "def get_punctuation_marks(text):\n",
    "    marks = re.findall('[' + re_punctuation + ']', text)\n",
    "    return ''.join(marks)\n",
    "\n",
    "def separate_languages(words):\n",
    "    rus = re.compile('^[а-яА-Я]+')\n",
    "    eng = re.compile('^[a-zA-Z]+')\n",
    "    \n",
    "    сyrillic = list(filter(rus.match, words))\n",
    "    latin = list(filter(eng.match, words))\n",
    "    return сyrillic, latin\n",
    "\n",
    "#число восклицательных и вопросительных знаков\n",
    "def calculate_emphasis(text):\n",
    "    еxclamation_points = re.findall('[!]', text)\n",
    "    question_marks = re.findall('[?]', text)\n",
    "    return (len(еxclamation_points), len(question_marks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_information:\n",
    "    def __init__(self, text=''):\n",
    "        self.text = text\n",
    "        self.words = word_tokenize(get_the_words(text))\n",
    "        self.marks = word_tokenize(get_punctuation_marks(text))\n",
    "        сyrillic, latin = separate_languages(self.words)\n",
    "        self.is_сyrillic = bool(сyrillic)\n",
    "        self.сyrillic = сyrillic\n",
    "        self.is_latin = bool(latin)\n",
    "        self.latin = latin       \n",
    "        self.emphasis = calculate_emphasis(text)\n",
    "        self.marks_statistics = FreqDist(self.marks)\n",
    "    \n",
    "    def word_statistics(self,meaningful = False,language = 'universal'): \n",
    "        if not meaningful:\n",
    "            if language == 'universal':\n",
    "                return FreqDist(self.words)\n",
    "            if language == 'russian':\n",
    "                if not self.is_сyrillic:\n",
    "                    raise LanguageException('No сyrillic words in the text')\n",
    "                return FreqDist(self.сyrillic)\n",
    "            if language == 'english':\n",
    "                if not self.is_latin:\n",
    "                    raise LanguageException('No latin words in the text')\n",
    "                return FreqDist(self.latin)\n",
    "            raise LanguageException('Language is not supported')\n",
    "        \n",
    "        return FreqDist(self.only_meaningful_words( language))\n",
    "        \n",
    "    def plot_word_statistic(self, number = 1, meaningful = False, language = 'universal'):\n",
    "        self.word_statistics(meaningful, language).plot(number)\n",
    "        \n",
    "\n",
    "        \n",
    "    def deviation_from_Zipf(self, meaningful = False, language = 'universal'):\n",
    "        frequencies = sorted(list(self.word_statistics(meaningful,language).values()), reverse = True)\n",
    "        frequencies = np.array(frequencies)\n",
    "        hypothesis = 1 / (np.arange(frequencies.size)+1) * frequencies[0]\n",
    "        #print(frequencies)\n",
    "        return np.std(frequencies - hypothesis)\n",
    "        \n",
    "    def plot_with_Zipf(self, meaningful = False, language = 'universal'):\n",
    "\n",
    "        frequencies = sorted(list(self.word_statistics(meaningful, language).values()), reverse = True)\n",
    "\n",
    "        hypothesis = 1 / (np.arange(len(frequencies))+1) * frequencies[0]\n",
    "        print('hypothesis:' ,hypothesis)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        plt.plot(range(1,len(frequencies)+1), frequencies)\n",
    "        plt.plot(range(1, len(frequencies)+1), hypothesis)\n",
    "        ax.set_xlabel('log порядкового номера слова')\n",
    "        ax.set_ylabel('log частоты')\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.plot()\n",
    "        \n",
    "    def only_meaningful_words(self, language = 'universal'):\n",
    "            \n",
    "        if language == 'universal':\n",
    "            return [x for x in self.words if x not in my_meaningless_words.universal]\n",
    "        elif language == 'russian':\n",
    "            if not self.is_сyrillic:\n",
    "                raise LanguageException('No сyrillic words in the text')\n",
    "            return [x for x in self.сyrillic if x not in my_meaningless_words.russian]\n",
    "        elif language == 'english':\n",
    "            if not self.is_latin:\n",
    "                raise LanguageException('No latin words in the text')\n",
    "            return [x for x in self.latin if x not in my_meaningless_words.english]\n",
    "        else: \n",
    "            raise LanguageException('Language is not supported')    \n",
    "            \n",
    "    \n",
    "    def percent_of_unique_words(self, meaningful = False, language = 'universal'):\n",
    "        D = self.some_statistic(meaningful, language)\n",
    "        return D['number_of_unique_words']/D['number_of_words'] *100\n",
    "    \n",
    "    def percent_of_meaningful_words(self, language = 'universal'):\n",
    "        return (self.some_statistic(meaningful = True, language=language)['number_of_words'] / \n",
    "    self.some_statistic(meaningful = False, language=language)['number_of_words'] *100)\n",
    "  \n",
    "    def number_of_words_occurring_n_times(self, meaningful = False,language = 'universal'):\n",
    "        Dict = self.word_statistics(meaningful,language)\n",
    "        New_Dict = defaultdict(int)\n",
    "        for value, items in itertools.groupby(sorted(Dict.items(), key=itemgetter(1)), key=itemgetter(1)):\n",
    "            New_Dict[value] = set(map(itemgetter(0), items))\n",
    "        return New_Dict\n",
    "\n",
    "    def plot_the_number_of_words_by_occurrence(self, meaningful = False,language = 'universal', logarithmic = False):\n",
    "        Dict = self.number_of_words_occurring_n_times(meaningful,language)\n",
    "        frequencies = []\n",
    "        quantities = []\n",
    "        \n",
    "        for x in sorted(Dict.keys()):\n",
    "            frequencies.append(x)\n",
    "            quantities.append(len(Dict[x]))\n",
    "        \n",
    "        #print(quantities)\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.plot(frequencies, quantities)\n",
    "        ax.set_xlabel('частота встречаемости слова')\n",
    "        ax.set_ylabel('количество слов данной частоты')\n",
    "        if logarithmic:\n",
    "            plt.xscale('log')\n",
    "            plt.yscale('log')\n",
    "        plt.plot()\n",
    "\n",
    "\n",
    "    def some_statistic(self, meaningful = False, language = 'universal'):\n",
    "        Dict = self.word_statistics(meaningful, language)\n",
    "        frequencies = list(Dict.values())\n",
    "\n",
    "        frequencies = np.array(frequencies)\n",
    "        F = {}\n",
    "        F['most_frequent'] = frequencies.max()\n",
    "        F['least_frequent'] = frequencies.min()\n",
    "        F['number_of_words'] = frequencies.sum()\n",
    "        F['number_of_different_words'] = frequencies.size\n",
    "        F['mean'] = np.mean(frequencies)\n",
    "        F['dispersion'] = np.std(frequencies)\n",
    "        F['median'] = np.median(frequencies)\n",
    "        F['number_of_unique_words'] = np.count_nonzero(frequencies == 1)\n",
    "        return F\n",
    "    \n",
    "    def percent_of_most_common_words(self,k = 20, meaningful = False, language = 'universal' ):\n",
    "        if k > 100 or k < 0:\n",
    "            raise LanguageException('it\\'s not a percentage')\n",
    "\n",
    "        frequencies = sorted(list(self.word_statistics(meaningful,language).values()), reverse = True)\n",
    "          \n",
    "        s = 0\n",
    "        for e in range(int(len(frequencies) * k / 100)):\n",
    "            s = s+ frequencies[e]\n",
    "        return (s / sum(frequencies)) * 100\n",
    "    \n",
    "    def phrases(self, length = 2, language = 'universal'):\n",
    "        if length == 1:\n",
    "            return self.words\n",
    "        \n",
    "        if language == 'universal':\n",
    "            prewords = self.words\n",
    "        elif language == 'russian':\n",
    "            if not self.is_сyrillic:\n",
    "                raise LanguageException('No сyrillic words in the text')\n",
    "            prewords = self.сyrillic\n",
    "        elif language == 'english':\n",
    "            if not self.is_latin:\n",
    "                raise LanguageException('No latin words in the text')\n",
    "            prewords = self.latin\n",
    "        else: \n",
    "            raise LanguageException('Language is not supported') \n",
    "        \n",
    "        word_groups = list(zip(*(prewords[i:-1] for i in range(length))))\n",
    "        return word_groups\n",
    "    \n",
    "    def phrases_statistics(self, length = 2, language = 'universal'):\n",
    "        if length==1:\n",
    "            return self.word_statistics(False, language)\n",
    "        return(FreqDist(self.phrases(length, language)))\n",
    "    \n",
    "    def plot_phrases_with_Zipf(self,length = 2, language = 'universal'):\n",
    "        if length ==1:\n",
    "            self.plot_with_Zipf(False, language)\n",
    "        else:\n",
    "            frequencies = sorted(list(self.phrases_statistics(length,language).values()), reverse = True)\n",
    "            hypothesis = 1 / (np.arange(len(frequencies))+1) * frequencies[0]\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.plot(range(1,len(frequencies)+1), frequencies)\n",
    "            plt.plot(range(1, len(frequencies)+1), hypothesis)\n",
    "            ax.set_xlabel('log порядкового номера слова')\n",
    "            ax.set_ylabel('log частоты')\n",
    "            plt.xscale('log')\n",
    "            plt.yscale('log')\n",
    "            plt.plot()\n",
    "\n",
    "            \n",
    "    def some_phrases_statistic(self, length = 2, language = 'universal'):\n",
    "        if length ==1:\n",
    "            return self.some_statistic(False, language) \n",
    "        Dict = self.phrases_statistics(length, language)\n",
    "        frequencies = list(Dict.values())\n",
    "        frequencies = np.array(frequencies)\n",
    "        F = {}\n",
    "        F['most_frequent'] = frequencies.max()\n",
    "        F['least_frequent'] = frequencies.min()\n",
    "        F['number_of_words'] = frequencies.sum()\n",
    "        F['number_of_different_words'] = frequencies.size\n",
    "        F['mean'] = np.mean(frequencies)\n",
    "        F['dispersion'] = np.std(frequencies)\n",
    "        F['median'] = np.median(frequencies)\n",
    "        F['number_of_unique_words'] = np.count_nonzero(frequencies == 1)\n",
    "        return F\n",
    "    \n",
    "    def plot_phrases_statistic(self,number = 1,length = 2, language = 'universal'):\n",
    "        if length ==1:\n",
    "             self.plot_word_statistic(number, False, language)\n",
    "        else:\n",
    "            self.phrases_statistics(length, language).plot(number)\n",
    "    \n",
    "    def number_of_phrases_occurring_n_times(self,length = 2, language = 'universal'):\n",
    "        if length ==1:\n",
    "            return self.number_of_words_occurring_n_times( meaningful = False,language=language)\n",
    "        Dict = self.phrases_statistics(length,language)\n",
    "        New_Dict = {}\n",
    "        for value, items in itertools.groupby(sorted(Dict.items(), key=itemgetter(1)), key=itemgetter(1)):\n",
    "            New_Dict[value] = set(map(itemgetter(0), items))\n",
    "        return New_Dict    \n",
    "    \n",
    "    \n",
    "    def plot_the_number_of_phrases_by_occurrence(self, length = 2, language = 'universal', logarithmic = False):\n",
    "        if length ==1:\n",
    "            self.plot_the_number_of_words_by_occurrence(meaningful = False, language=language, logarithmic=logarithmic)\n",
    "        else:\n",
    "            Dict = self.number_of_phrases_occurring_n_times(length,language)\n",
    "            frequencies = []\n",
    "            quantities = []\n",
    "        \n",
    "            for x in sorted(Dict.keys()):\n",
    "                frequencies.append(x)\n",
    "                quantities.append(len(Dict[x]))\n",
    "        \n",
    "            #print(quantities)\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.plot(frequencies, quantities)\n",
    "            ax.set_xlabel('частота встречаемости слова')\n",
    "            ax.set_ylabel('количество слов данной частоты')\n",
    "            if logarithmic:\n",
    "                plt.xscale('log')\n",
    "                plt.yscale('log')\n",
    "            plt.plot()\n",
    "            \n",
    "            \n",
    "    def cloud(self,  meaningful = False,language = 'universal' ):\n",
    "        if not meaningful:\n",
    "            if language == 'universal':\n",
    "                wcloud = WordCloud().generate(' '.join(self.words))\n",
    "            elif language == 'russian':\n",
    "                if not self.is_сyrillic:\n",
    "                    raise LanguageException('No сyrillic words in the text')\n",
    "                wcloud = WordCloud().generate(' '.join(self.сyrillic))\n",
    "            elif language == 'english':\n",
    "                if not self.is_latin:\n",
    "                    raise LanguageException('No latin words in the text')\n",
    "                wcloud = WordCloud().generate(' '.join(self.latin))\n",
    "            else: \n",
    "                raise LanguageException('Language is not supported') \n",
    "                \n",
    "            \n",
    "        else:\n",
    "            wcloud = WordCloud().generate(' '.join(self.only_meaningful_words(language)))\n",
    "            \n",
    "        plt.imshow(wcloud  , interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
